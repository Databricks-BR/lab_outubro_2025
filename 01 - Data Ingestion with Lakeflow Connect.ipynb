{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b29ac4ac-1f15-4d05-b3df-2bf6ead4856b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://raw.githubusercontent.com/Databricks-BR/lab_outubro_2025/refs/heads/main/Includes/images/handson_lab_outubro.png\" alt=\"Databricks Learning\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99f1429d-a388-4b15-b4de-fd250880b96d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 1 - Ingestão de Dados com LakeFlow Connect\n",
    "\n",
    "Nesta demonstração, você será apresentado aos conectores gerenciados **LakeFlow Connect** para fontes empresariais externas. Uma ferramenta fácil de usar para trazer dados de diversos sistemas, como bancos de dados (por exemplo, SQL Server), aplicativos (por exemplo, Salesforce, Workday) e serviços de armazenamento de arquivos (por exemplo, SharePoint) para o lakehouse.\n",
    "\n",
    "Ela foi projetada para lidar com dados de forma eficiente e melhorar automaticamente o desempenho.\n",
    "\n",
    "### Objetivos de Aprendizagem\n",
    "\n",
    "Ao final da demonstração, você deverá ser capaz de:\n",
    "\n",
    "- Explorar os conectores gerenciados pela Databricks disponíveis para ingerir dados via LakeFlow Connect.\n",
    "- Ver como ingerir dados usando o Partner Connect.\n",
    "- Adicionar um conector de banco de dados e configurar uma demonstração de pipeline de ingestão:\n",
    "  - Escolher quais dados você deseja ingerir e sincronizar com a Databricks\n",
    "  - Sincronizar o pipeline de dados com o Unity Catalog (catálogo e esquema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c79cf5e6-15cf-4b64-9dfc-17ff53a4a6ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Complete as etapas a seguir para visualizar a documentação do Lakeflow Connect:\n",
    "\n",
    "   a. Acesse a página da [documentação Databricks](https://docs.databricks.com/aws/en/).\n",
    "\n",
    "   b. Na barra de navegação à esquerda, expanda **Data Engineering**.\n",
    "\n",
    "   c. Expanda **Lakeflow Connect** para visualizar a documentação disponível sobre ingestão de dados com Lakeflow Connect.\n",
    "\n",
    "   d. Expanda **Managed Connectors** para acessar informações sobre conectores gerenciados pela Databricks.\n",
    "\n",
    "**NOTA:** As instruções de navegação na documentação podem mudar após uma atualização."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9567f6cd-9c58-40f3-b84b-3ad64eb840a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. Complete as etapas a seguir para explorar as capacidades de **Ingestão de Dados** disponíveis no Databricks:\n",
    "\n",
    "   a. Na barra de navegação principal à esquerda, clique com o botão direito em **Ingestão de Dados** e selecione **Abrir em uma Nova Guia**.\n",
    "\n",
    "   b. Em **Conectores Databricks**, você verá vários conectores gerenciados pela Databricks fornecidos pelo LakeFlow Connect.\n",
    "\n",
    "   c. Na seção **Arquivos**, você pode:\n",
    "   \n",
    "   - **Criar ou modificar tabelas**\n",
    "\n",
    "   - **Fazer upload de arquivos para um volume**\n",
    "\n",
    "   - **Criar uma tabela a partir do Amazon S3**\n",
    "   \n",
    "   - Arrastar e soltar arquivos ao usar as opções para criar/modificar tabelas ou fazer upload de arquivos para um volume.\n",
    "\n",
    "   d. Em **Conectores Fivetran**, você pode pesquisar conexões de fontes de dados específicas usando um parceiro.\n",
    "\n",
    "   e. Clique em qualquer conector para ver os detalhes.\n",
    "\n",
    "   f. Você também pode fazer upload de arquivos diretamente para o **DBFS** para compatibilidade retroativa, embora o Databricks recomende fazer upload para o Unity Catalog daqui para frente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26a484b3-1339-44fe-bef2-15c2c9cd42a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3. Complete a demonstração a seguir para aprender como usar um conector gerenciado Databricks para um banco de dados externo ou aplicativo SaaS usando o **LakeFlow Connect**.\n",
    "\n",
    "      **NOTA:** Este curso não possui um banco de dados ou aplicativo SaaS ativo para uso. As demonstrações abaixo são apenas um passo a passo. Durante uma aula ao vivo, escolha um dos tours abaixo.\n",
    "\n",
    "   - [Demonstração de Conector Gerenciado LakeFlow Connect](https://app.getreprise.com/launch/BXZY58n/) - Demonstração simples\n",
    "\n",
    "   - [Databricks Lakeflow Connect para Relatórios Workday: Conecte, Ingerira e Analise Dados Workday Sem Complexidade](https://www.databricks.com/resources/demos/tours/appdev/lakeflow-workday-connect?itm_data=demo_center)\n",
    "\n",
    "   - [Databricks Lakeflow Connect para Salesforce: Potencializando Vendas Inteligentes com IA e Analytics](https://www.databricks.com/resources/demos/tours/platform/discover-databricks-lakeflow-connect-demo?itm_data=demo_center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f992174-db94-4d65-8b62-6754acfa8ae3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "&copy; 2025 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"blank\">Apache Software Foundation</a>.<br/>\n",
    "<br/><a href=\"https://databricks.com/privacy-policy\" target=\"blank\">Privacy Policy</a> | \n",
    "<a href=\"https://databricks.com/terms-of-use\" target=\"blank\">Terms of Use</a> | \n",
    "<a href=\"https://help.databricks.com/\" target=\"blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "01 - Data Ingestion with Lakeflow Connect",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
